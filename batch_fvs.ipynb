{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Asynchronous parallel processing of FVS keyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import ipyparallel as ipp\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A function to execute FVS that will be mapped to all keyfiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_fvs(keyfile):\n",
    "    fvs_exe = 'C:\\\\FVSbin\\\\'+os.path.split(keyfile)[-1][:5]+'.exe'\n",
    "    subprocess.call([fvs_exe, '--keywordfile='+keyfile]) # run fvs\n",
    "    \n",
    "    base_dir = os.path.split(keyfile)[0]\n",
    "    base_name = os.path.split(keyfile)[-1].split('.')[0]\n",
    "    \n",
    "    # clean-up the outputs\n",
    "    # move the .out and .key file\n",
    "    path = os.path.join(base_dir, 'completed','keyfiles')\n",
    "    if not os.path.exists(path): \n",
    "        os.makedirs(path)\n",
    "    shutil.move(keyfile, os.path.join(base_dir,'completed','keyfiles'))\n",
    "    path = os.path.join(base_dir, 'completed','outfiles')\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    shutil.move(os.path.join(base_dir,base_name+'.out'), os.path.join(base_dir,'completed','outfiles'))\n",
    "    \n",
    "    # delete the other files\n",
    "    os.remove(os.path.join(base_dir, base_name+'.trl'))\n",
    "    return keyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Run the following command in a command prompt to start up a cluster of workers:\n",
    "\n",
    "`>> activate Py3.5 # or other environment name`\n",
    "\n",
    "`(Py3.5)>> ipcluster start -n 4 # or other number of cores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a hub to control the workers\n",
    "c = ipp.Client()\n",
    "c.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# if you want to run a single keyfile, use this\n",
    "# subprocess.call(['C:\\\\FVSbin\\\\FVSpn.exe', '--keywordfile=C:\\\\GitHub\\\\FSC_Case_Studies\\\\keyfiles_to_run\\\\PN\\\\fvsPN_stand1_rx4_off0.key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a direct view of the workers and a load-balanced view for submitting jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing subprocess on engine(s)\n",
      "importing shutil on engine(s)\n",
      "importing os on engine(s)\n"
     ]
    }
   ],
   "source": [
    "dv = c[:] # direct view\n",
    "v = c.load_balanced_view() # load-balanced view\n",
    "\n",
    "# import packages to all workers\n",
    "with dv.sync_imports():\n",
    "    import subprocess\n",
    "    import shutil\n",
    "    import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Execute an ayschronous batch of FVS runs for all the keyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,859 keyfiles found.\n"
     ]
    }
   ],
   "source": [
    "# gather the list of keyfiles to run\n",
    "run_dir = os.path.abspath('keyfiles_to_run')\n",
    "to_run = glob.glob(os.path.join(run_dir, '*.key'))\n",
    "print('{:,}'.format(len(to_run)), 'keyfiles found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started batch processing.\n"
     ]
    }
   ],
   "source": [
    "# start asynchronous batch with load-balanced view\n",
    "res = v.map_async(run_fvs, to_run)\n",
    "print('Started batch processing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Monitor progress of batch run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9d384174cc4846a63d3c7d9b57b941"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Default method\n",
    "# res.wait_interactive()\n",
    "\n",
    "# OR USE A PROGRESS BAR!\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "\n",
    "runs_done = res.progress\n",
    "with tqdm_notebook(total=len(res), initial=runs_done, desc='FVS Run Progress', unit='keyfile') as pbar:\n",
    "    new_progress = res.progress - runs_done\n",
    "    runs_done += new_progress\n",
    "    pbar.update(new_progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Return a true/false if full set of jobs completed\n",
    "# res.ready()\n",
    "\n",
    "# Cancels the batch (wait for fvs executables to complete)\n",
    "# res.abort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Human time spent:', res.wall_time)\n",
    "print('Computer time spent:', res.serial_time)\n",
    "print('Async speedup:', res.serial_time/res.wall_time)\n",
    "print('Human time per FVS run:', res.wall_time/res.progress)\n",
    "print('Computer time per FVS run:', res.serial_time/res.progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inspect how processing speed per run changed as batch progressed\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "time_steps = [(t2 - t1).total_seconds() for t2, t1 in zip(res.received, res.submitted)]\n",
    "plt.plot(time_steps)\n",
    "plt.ylabel('time per run')\n",
    "plt.xlabel('runs completed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# shut down the parallel workers\n",
    "c.shutdown(hub=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for runs that didn't complete successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# import pandas as pd\n",
    "# conn = psycopg2.connect(\"dbname='FVSOut' user='postgres' host='localhost'\") # password in pgpass file\n",
    "# SQL = '''\n",
    "# SELECT keywordfile\n",
    "# FROM fvs_cases;\n",
    "# '''\n",
    "# # read the query into a pandas dataframe\n",
    "# completed = pd.read_sql(SQL, conn)\n",
    "\n",
    "# # close the database connection\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# completed['keyfile'] = completed.keywordfile.apply(lambda x: os.path.split(x)[-1] + '.key')\n",
    "# completed.keyfile.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# completed_keys = glob.glob('C:\\\\GitHub\\\\FSC_Case_Studies\\\\keyfiles_to_run\\\\PN\\\\completed\\\\keyfiles\\\\*.key')\n",
    "# completed_basenames = [os.path.split(x)[-1] for x in completed_keys]\n",
    "# print(len(completed), 'keyfiles in database')\n",
    "# print(len(completed_basenames), 'keyfiles in completed folder')\n",
    "\n",
    "# for keyfile in completed.keyfile.values: # keyfiles recorded in the DB\n",
    "#     if keyfile not in completed_basenames:\n",
    "#         print(keyfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# failed = glob.glob('C:\\\\GitHub\\\\FSC_Case_Studies\\\\keyfiles_to_run\\\\PN\\\\completed\\\\outfiles\\\\failed\\\\*.out')\n",
    "# failed_basenames = [os.path.split(x)[-1].split('.')[0] for x in failed]\n",
    "# moved = glob.glob('C:\\\\GitHub\\\\FSC_Case_Studies\\\\keyfiles_to_run\\\\*.key')\n",
    "# moved_basenames = [os.path.split(x)[-1].split('.')[0] for x in moved]\n",
    "# for path in moved:\n",
    "#     if os.path.split(path)[-1].split('.')[0] not in failed_basenames:\n",
    "#         print(path, \"not in failed, but was moved\")\n",
    "# for path in failed:\n",
    "#     if os.path.split(path)[-1].split('.')[0] not in moved_basenames:\n",
    "#         print(path, \"not in moved, but failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Py3.5]",
   "language": "python",
   "name": "conda-env-Py3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
