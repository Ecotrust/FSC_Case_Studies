{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Asynchronous parallel processing of FVS keyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import ipyparallel as ipp\n",
    "import shutil\n",
    "from tqdm import tqdm_notebook\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to execute FVS that will be mapped to all keyfiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fvs(keyfile):\n",
    "    fvs_exe = 'C:\\\\FVSbin\\\\'+os.path.split(keyfile)[-1][:5]+'.exe'\n",
    "    subprocess.call([fvs_exe, '--keywordfile='+keyfile]) # run fvs\n",
    "    \n",
    "    base_dir = os.path.split(keyfile)[0]\n",
    "    base_name = os.path.split(keyfile)[-1].split('.')[0]\n",
    "    \n",
    "    # clean-up the outputs\n",
    "    # move the .out and .key file\n",
    "#     path = os.path.join(base_dir, 'organon_tests_completed','keyfiles')\n",
    "#     if not os.path.exists(path): \n",
    "#         os.makedirs(path)\n",
    "#     shutil.move(keyfile, os.path.join(base_dir,'organon_tests_completed','keyfiles'))\n",
    "#     path = os.path.join(base_dir, 'organon_tests_completed','outfiles')\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "#     shutil.move(os.path.join(base_dir,base_name+'.out'), os.path.join(base_dir,'organon_tests_completed','outfiles'))\n",
    "    \n",
    "    # delete the other files\n",
    "    os.remove(os.path.join(base_dir, base_name+'.trl'))\n",
    "    return keyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command in a command prompt to start up a cluster of workers:\n",
    "\n",
    "`>> activate my_env # or other environment name`\n",
    "\n",
    "`(my_env)>> ipcluster start -n 4 # or other number of cores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a hub to control the workers\n",
    "c = ipp.Client()\n",
    "c.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to run a single keyfile, use this\n",
    "# subprocess.call(['C:\\\\FVSbin\\\\FVSop.exe', '--keywordfile=C:\\\\GitHub\\\\FSC_Case_Studies\\\\keyfiles_to_run\\\\fvsOP_stand12_rx1_off0.key'])\n",
    "\n",
    "# as another example, for serial (not parallel) processing of some keyfiles without cleaning up output files:\n",
    "# for keyfile in to_run:\n",
    "#     run_fvs(keyfile)\n",
    "    #subprocess.call(['C:\\\\FVSbin\\\\FVSpn.exe', '--keywordfile='+keyfile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a direct view of the workers and a load-balanced view for submitting jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing subprocess on engine(s)\n",
      "importing shutil on engine(s)\n",
      "importing os on engine(s)\n"
     ]
    }
   ],
   "source": [
    "dv = c[:] # direct view\n",
    "v = c.load_balanced_view() # load-balanced view\n",
    "\n",
    "# import packages to all workers\n",
    "with dv.sync_imports():\n",
    "    import subprocess\n",
    "    import shutil\n",
    "    import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute an ayschronous batch of FVS runs for all the keyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 keyfiles found.\n"
     ]
    }
   ],
   "source": [
    "# gather the list of keyfiles to run\n",
    "run_dir = os.path.abspath('keyfiles_to_run')\n",
    "to_run = glob.glob(os.path.join(run_dir, '*.key'))\n",
    "print('{:,}'.format(len(to_run)), 'keyfiles found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run = to_run * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started batch processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b782ec8b9a4406b4d13a335d238812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='FVS Run Progress', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddiaz\\AppData\\Local\\Continuum\\miniconda3\\envs\\fvs\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start asynchronous batch with load-balanced view\n",
    "res = v.map_async(run_fvs, to_run)\n",
    "print('Started batch processing.')\n",
    "\n",
    "runs_done = res.progress\n",
    "with tqdm_notebook(total=len(res), initial=runs_done, desc='FVS Run Progress', unit='keyfile') as pbar:\n",
    "    while not res.ready():\n",
    "        new_progress = res.progress - runs_done\n",
    "        runs_done += new_progress\n",
    "        pbar.update(new_progress)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timefmt(seconds):\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return '{:.0f} hours, {:.0f} minutes, {:.1f} seconds'.format(h,m,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Human time spent:', timefmt(res.wall_time))\n",
    "print('Computer time spent:', timefmt(res.serial_time))\n",
    "print('Async speedup:', '{:.2f}x'.format(res.serial_time/res.wall_time))\n",
    "print('Human time per FVS run:', '{:.2f} seconds'.format(res.wall_time/res.progress))\n",
    "print('Computer time per FVS run:', '{:.2f} seconds'.format(res.serial_time/res.progress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a true/false if full set of jobs completed\n",
    "# res.ready()\n",
    "\n",
    "# Cancels the batch (wait for fvs executables to complete)\n",
    "res.abort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shut down the parallel workers\n",
    "# c.shutdown(hub=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
